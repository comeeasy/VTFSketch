{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from src.models import FPathPredictor\n",
    "from src.dataloaders import FPathDataset\n",
    "from src.losses import FocalLoss, SketchMaskLoss\n",
    "\n",
    "from src.utils import inference, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vtf.shape=(1024, 1024, 21), target.shape=torch.Size([1024, 1024, 1])\n",
      "type(vtf)=<class 'numpy.ndarray'>, type(target)=<class 'torch.Tensor'>\n",
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.]]])\n"
     ]
    }
   ],
   "source": [
    "BATCHSIZE = 16\n",
    "\n",
    "train_yaml  = \"/home/joono/fpath_infodraw/dataset/train.yaml\"\n",
    "val_yaml    = \"/home/joono/fpath_infodraw/dataset/val.yaml\"\n",
    "test_yaml   = \"/home/joono/fpath_infodraw/dataset/test.yaml\"\n",
    "\n",
    "train_dset  = FPathDataset(train_yaml)\n",
    "valid_dset  = FPathDataset(val_yaml)\n",
    "test_dset   = FPathDataset(test_yaml)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dset,\n",
    "    batch_size=BATCHSIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=16,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    valid_dset,\n",
    "    batch_size=BATCHSIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=16,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dset,\n",
    "    batch_size=BATCHSIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "vtf, target = train_dset[0]\n",
    "print(f\"{vtf.shape=}, {target.shape=}\")\n",
    "print(f\"{type(vtf)=}, {type(target)=}\")\n",
    "print(f\"{target[:3, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the accelerator\n",
    "\n",
    "def train(model, optimizer, objective, train_loader, accelerator):\n",
    "    model, optimizer, train_loader = accelerator.prepare(model, optimizer, train_loader)\n",
    "    model = model.train()\n",
    "    \n",
    "    cum_loss = 0\n",
    "    for vtf, target in tqdm(train_loader):\n",
    "        vtf = vtf.to(accelerator.device) # [B x W x H x 21]\n",
    "        target = target.to(accelerator.device)\n",
    "        \n",
    "        pred_target = model(vtf) # [B x W x H x 1]\n",
    "        \n",
    "        loss = objective(pred_target, target)\n",
    "        cum_loss += loss.detach().item() / len(train_loader)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "    print(f\"train loss: {cum_loss}\")\n",
    "\n",
    "def val(model, objective, val_loader, epoch, accelerator, save_path='checkpoints/best_model.pth'):\n",
    "    model, val_loader = accelerator.prepare(model, val_loader)\n",
    "    model = model.eval()\n",
    "    cum_loss = 0\n",
    "    best_val_loss = 1e4\n",
    "    with torch.no_grad():\n",
    "        for vtf, target in tqdm(val_loader):\n",
    "            vtf = vtf.to(accelerator.device) # [B x W x H x 21]\n",
    "            target = target.to(accelerator.device)\n",
    "        \n",
    "            pred_target = model(vtf) # [B x W x H x 1]\n",
    "        \n",
    "            loss = objective(pred_target, target)\n",
    "            cum_loss += loss.detach().item() / len(val_loader)\n",
    "            \n",
    "    print(f\"val loss: {cum_loss}\")\n",
    "\n",
    "    # Check if the current validation loss is the best we've seen\n",
    "    if cum_loss < best_val_loss:\n",
    "        best_val_loss = cum_loss\n",
    "        torch.save(model.state_dict(), f\"checkpoints/best_model_epoch{epoch}.pt\")\n",
    "        print(f\"Model saved with validation loss: {cum_loss:.4f}\")\n",
    "\n",
    "def test(model, test_loader, accelerator):\n",
    "    model, test_loader = accelerator.prepare(model, test_loader)\n",
    "    model = model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for vtf, target in tqdm(test_loader):\n",
    "            vtf = vtf.to(accelerator.device)\n",
    "            target = target.to(accelerator.device)\n",
    "            \n",
    "            pred_target = inference(model, vtf)\n",
    "\n",
    "            all_preds.append(pred_target.cpu().numpy())\n",
    "            all_targets.append(target.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds).flatten()\n",
    "    all_targets = np.concatenate(all_targets).flatten()\n",
    "    all_preds = 1 - all_preds # 스케치(검정==0)와 배경(흰색==1) 을 역전\n",
    "    all_targets = 1 - all_targets # 스케치(검정==0)와 배경(흰색==1) 을 역전\n",
    "\n",
    "    precision = precision_score(all_targets, all_preds)\n",
    "    recall = recall_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 15\u001b[0m     train(model, optimizer, objective, train_loader, accelerator)\n\u001b[1;32m     16\u001b[0m     val(model, objective, val_loader, epoch, accelerator)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, objective, train_loader, accelerator)\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      7\u001b[0m cum_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vtf, target \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m      9\u001b[0m     vtf \u001b[38;5;241m=\u001b[39m vtf\u001b[38;5;241m.\u001b[39mto(accelerator\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;66;03m# [B x W x H x 21]\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(accelerator\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/home/joono/anaconda3/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/home/joono/anaconda3/lib/python3.11/site-packages/accelerate/data_loader.py:454\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/home/joono/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/home/joono/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/home/joono/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_get_data()\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/home/joono/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/home/joono/anaconda3/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/home/joono/anaconda3/lib/python3.11/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout)\n",
      "File \u001b[0;32m/home/joono/anaconda3/lib/python3.11/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m wait([\u001b[38;5;28mself\u001b[39m], timeout)\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/home/joono/anaconda3/lib/python3.11/multiprocessing/connection.py:947\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    944\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 947\u001b[0m     ready \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mselect(timeout)\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/home/joono/anaconda3/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = FPathPredictor().to('cuda')\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# objective = nn.CrossEntropyLoss().to('cuda')\n",
    "# objective = FocalLoss(alpha=10000, gamma=100).to('cuda') # gamma = focusing factor, easy negative case에 대하여 더 큰 패널티를 줌.\n",
    "# objective = nn.MSELoss().to('cuda')\n",
    "# objective = nn.BCEWithLogitsLoss().to('cuda')\n",
    "objective = SketchMaskLoss().to('cuda')\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(model, optimizer, objective, train_loader, accelerator)\n",
    "    val(model, objective, val_loader, epoch, accelerator)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        test(model, test_loader, accelerator)\n",
    "                \n",
    "test(model, test_loader, accelerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtf, _ = test_dset[0]\n",
    "\n",
    "pixel_vtf = vtf[100, 100]\n",
    "pixel_vtf = torch.tensor(pixel_vtf).to('cuda')\n",
    "\n",
    "pred_target = inference_logits(model, pixel_vtf.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtf, _ = test_dset[0]\n",
    "\n",
    "vtf = torch.tensor(vtf).to('cuda')\n",
    "\n",
    "pred_target = inference_logits(model, vtf.unsqueeze(0))\n",
    "\n",
    "result = pred_target.squeeze().detach().cpu().numpy()\n",
    "print(f\"{np.min(result)=}, {np.max(result)=}\")\n",
    "# _min, _max = np.min(result), np.max(result)\n",
    "# result -= _min\n",
    "# result /= (_max - _min)\n",
    "# result = (result > 0.9) \n",
    "\n",
    "plt.ylim(-1, 100)\n",
    "plt.xlim(0, 1)\n",
    "plt.hist(result, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sktch = result.transpose((1, 0)) > 0.5\n",
    "\n",
    "cv2.imwrite(\"sktch.png\", pred_sktch * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result.transpose((1, 0)) > 0.5, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGBtoGray_conversion_weights = np.array([0.2989, 0.5870, 0.1140], dtype=np.float32)\n",
    "BGRtoGray_conversion_weights = np.array([0.1140, 0.5870, 0.2989], dtype=np.float32)\n",
    "\n",
    "input_fpath_test = \"/home/joono/fpath_infodraw/dataset/test/fpath_npzs/color_901_fpath_of_infodraw.npz\"\n",
    "# info_test = \"/home/joono/fpath_infodraw/dataset/test/imgs/color_902/color_902_infodraw.png\"\n",
    "target_test = \"/home/joono/fpath_infodraw/dataset/test/targets/line_903.png\"\n",
    "threshold = 0.8\n",
    "\n",
    "output_png_file_name = f\"circle_903_{threshold}.png\"\n",
    "\n",
    "\n",
    "# load target image\n",
    "target_img = Image.open(target_test).convert('L')\n",
    "target_img = np.array(target_img)\n",
    "\n",
    "W, H = target_img.shape\n",
    "raio_of_black = (np.sum(target_img < 0.01) / (W * H))\n",
    "\n",
    "print(f\"{np.sum(target_img < 0.01)}, {W=}, {H=} {raio_of_black=}\")\n",
    "\n",
    "# load fpath\n",
    "input_fpath = np.load(input_fpath_test)\n",
    "fpath_tensor = torch.tensor(input_fpath[\"data\"])\n",
    "\n",
    "W, H, L, C = fpath_tensor.shape\n",
    "if C == 3:\n",
    "    input_fpath_gray = np.dot(fpath_tensor, BGRtoGray_conversion_weights)\n",
    "    fpath_tensor = torch.tensor(input_fpath_gray)\n",
    "\n",
    "fpath_tensor = fpath_tensor.squeeze()\n",
    "print(fpath_tensor.shape)\n",
    "fpath_tensor = fpath_tensor.unsqueeze(0)\n",
    "print(fpath_tensor.shape)\n",
    "fpath_tensor = fpath_tensor.to('cuda')\n",
    "\n",
    "# input = torch.tensor(input).to('cuda')\n",
    "# info_img = torch.tensor(info_img).to('cuda')\n",
    "\n",
    "# inference result\n",
    "model = model.eval()\n",
    "pred_target = model(fpath_tensor)\n",
    "pred_target = nn.functional.softmax(pred_target, dim=3)\n",
    "\n",
    "print(f\"{pred_target.shape=}\")\n",
    "\n",
    "print(f\"{torch.min(pred_target[0, :, :, 0]).item()}, {torch.max(pred_target[0, :, :, 0]).item()}, {torch.min(pred_target[0, :, :, 1]).item()}, {torch.max(pred_target[0, :, :, 1]).item()}\")\n",
    "    \n",
    "pred_target = pred_target.squeeze()\n",
    "pred_target = pred_target.detach().cpu().numpy()\n",
    "\n",
    "print(f\"{pred_target.shape=}\")\n",
    "\n",
    "result = pred_target.transpose(2, 1, 0)\n",
    "\n",
    "canvas = np.zeros((W, H))\n",
    "canvas[np.where(result[:, :, 1] > 0.5)] = 0\n",
    "canvas[np.where(result[:, :, 1] <= 0.5)] = 255\n",
    "print(f\"{np.min(canvas)=}, {np.max(canvas)=}\")\n",
    "\n",
    "plt.imshow(canvas, cmap='gray')\n",
    "cv2.imwrite(\"res.png\", canvas)\n",
    "\n",
    "# load infodraw img\n",
    "# infodraw_test_img = Image.open(info_test).convert('L')\n",
    "# infodraw_test_img = target_transforms(infodraw_test_img) \n",
    "# infodraw_test_img = infodraw_test_img.squeeze().numpy()\n",
    "\n",
    "# # load target img\n",
    "# target_img = Image.open(target_test).convert('L')\n",
    "# target_img = target_transforms(target_img) \n",
    "# target_img = target_img.squeeze().numpy()\n",
    "\n",
    "# # calculate pred target\n",
    "# info_plus_error = infodraw_test_img + output\n",
    "# output = normalize(output)\n",
    "# mask_for_noise_filtering = infodraw_test_img < threshold\n",
    "\n",
    "# result = output * mask_for_noise_filtering\n",
    "# canvas = np.ones_like(output, np.float32)\n",
    "# canvas[np.where(mask_for_noise_filtering)] = result[np.where(mask_for_noise_filtering)]\n",
    "\n",
    "# error = target_img - info_plus_error\n",
    "\n",
    "# canvas = np.concatenate([output, infodraw_test_img, info_plus_error, error], axis=1)\n",
    "# plt.imshow(canvas, cmap=\"gray\")\n",
    "# cv2.imwrite(output_png_file_name, canvas * 255)\n",
    "# cv2.imwrite(\"res.png\", info_plus_error * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(result[:, :, 0] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = FPathDataset(\"/home/joono/fpath_infodraw/dataset/fpath_target_train.yaml\", transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infodraw_test_img = Image.open(info_test).convert('L')\n",
    "infodraw_test_img = target_transforms(infodraw_test_img) \n",
    "\n",
    "input_fpath = np.load(input_fpath_test)['data'].squeeze()\n",
    "\n",
    "infodraw_test_img = infodraw_test_img.numpy().transpose(1, 2, 0)\n",
    "\n",
    "input_fpath.shape, infodraw_test_img.shape\n",
    "\n",
    "input = np.concatenate([input_fpath, infodraw_test_img], axis=2)\n",
    "\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((2, 3, 4, 5)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((2, 2)) *  10\n",
    "target = torch.tensor([[1., 0.], [1., 1.]])\n",
    "mask = torch.tensor([[1, 0], [1, 1]])\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss(reduce='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "\n",
    "a = torch.sigmoid(a)\n",
    "\n",
    "print(a)\n",
    "\n",
    "l = -(target * torch.log(a) + (1-target) * torch.log(1-a))\n",
    "print(l)\n",
    "l = (1/torch.sum(mask)) * torch.sum(mask * l) + (1/torch.sum(1-mask)) * torch.sum((1-mask) * l)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
