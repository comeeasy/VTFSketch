{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.init as init\n",
    "\n",
    "from src.unet.unet_models import UNet\n",
    "from src.models import VTFPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VTFPredictor(model_name=\"FPathPredictor\", loss_name=\"SketchMaskLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "fc1 = nn.Linear(21, 1, bias=False)\n",
    "init.constant_(fc1.weight.data, 0.1)\n",
    "print(fc1.weight.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "fc1 = nn.Linear(21, 1, bias=False)\n",
    "init.constant_(fc1.weight.data, 0.1)\n",
    "print(fc1.weight.data.shape) \n",
    "\n",
    "infodraw = torch.ones(1, 1, 3, 3)\n",
    "infodraw[0, 0, 2, 0] = 0.7\n",
    "infodraw[0, 0, 2, 1] = 0.8\n",
    "infodraw[0, 0, 2, 2] = 0.9\n",
    "\n",
    "threshold = 0.99\n",
    "mask = infodraw < threshold\n",
    "\n",
    "fpath = torch.ones(1, 21, 3, 3) / 21\n",
    "fpath_perm = fpath.permute(0, 2, 3, 1)\n",
    "y_hat_perm = fc1(fpath_perm)\n",
    "y_hat = y_hat_perm.permute(0, 3, 1, 2)\n",
    "\n",
    "masked_y_hat = mask * y_hat\n",
    "masked_infodraw = ~mask * infodraw\n",
    "\n",
    "result = masked_y_hat + masked_infodraw\n",
    "\n",
    "print(f\"fpath       : {fpath.shape}\")\n",
    "print(f\"fpath_perm  : {fpath_perm.shape}, After permute(0, 2, 3, 1)\")\n",
    "print(f\"y_hat_perm  : {y_hat_perm.shape}, After nn.Linear(21, 1)\")\n",
    "print(f\"y_hat       : {y_hat.shape}, After permute(0, 3, 1, 2)\")\n",
    "\n",
    "print(f\"infodraw        : \\n{infodraw}\")\n",
    "print(f\"mask            : \\n{mask}\")\n",
    "print(f\"~mask           : \\n{~mask}\")\n",
    "print(f\"masked_y_hat    : \\n{masked_y_hat}\")\n",
    "print(f\"masked_infodraw : \\n{masked_infodraw}\")\n",
    "print(f\"result          : \\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath[0, :, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "fc1 = nn.Linear(21, 1, bias=False)\n",
    "init.constant_(fc1.weight.data, 0.1)\n",
    "print(fc1.weight.data.shape)\n",
    "\n",
    "infodraw = torch.ones(1, 1, 3, 3)\n",
    "infodraw[0, 0, 2, 0] = 0.7\n",
    "infodraw[0, 0, 2, 1] = 0.8\n",
    "infodraw[0, 0, 2, 2] = 0.9\n",
    "\n",
    "threshold = 0.99\n",
    "\n",
    "B, _, H, W = infodraw.shape\n",
    "result = infodraw.clone()\n",
    "fpath = torch.ones(1, 21, 3, 3) / 21\n",
    "fpath_list = []\n",
    "for b in range(B):\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            if infodraw[b, :, h, w].item() < threshold:\n",
    "                # print((infodraw[b, :, h, w], (h, w)))\n",
    "                fpath_list.append((fpath[b, :, h, w], (h, w)))  \n",
    "\n",
    "    for fpath_vec, (h, w) in fpath_list:\n",
    "        y_hat = fc1(fpath_vec.unsqueeze(0))\n",
    "        result[b, 0, h, w] = y_hat\n",
    "\n",
    "print(f\"result: \\n{result}\")\n",
    "\n",
    "# fpath_perm = fpath.permute(0, 2, 3, 1)\n",
    "# y_hat_perm = fc1(fpath_perm)\n",
    "# y_hat = y_hat_perm.permute(0, 3, 1, 2)\n",
    "\n",
    "# masked_y_hat = mask * y_hat\n",
    "# masked_infodraw = ~mask * infodraw\n",
    "\n",
    "# result = masked_y_hat + masked_infodraw\n",
    "\n",
    "# print(f\"fpath       : {fpath.shape}\")\n",
    "# print(f\"fpath_perm  : {fpath_perm.shape}, After permute(0, 2, 3, 1)\")\n",
    "# print(f\"y_hat_perm  : {y_hat_perm.shape}, After nn.Linear(21, 1)\")\n",
    "# print(f\"y_hat       : {y_hat.shape}, After permute(0, 3, 1, 2)\")\n",
    "\n",
    "# print(f\"infodraw        : \\n{infodraw}\")\n",
    "# print(f\"mask            : \\n{mask}\")\n",
    "# print(f\"~mask           : \\n{~mask}\")\n",
    "# print(f\"masked_y_hat    : \\n{masked_y_hat}\")\n",
    "# print(f\"masked_infodraw : \\n{masked_infodraw}\")\n",
    "# print(f\"result          : \\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = torch.tensor([[[\n",
    "    [1.0, 0.6, 0.1],\n",
    "    [0.5, 0.0, 0.9],\n",
    "    [0.2, 0.7, 1.0]\n",
    "]]])\n",
    "y = torch.tensor([[[\n",
    "    [1, 1, 0],\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1]\n",
    "]]])\n",
    "print(f\"y_hat   : {y_hat.shape}\")\n",
    "print(f\"y       : {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_pixel = -(y * torch.log(y_hat+1e-8) + (1-y) * torch.log(1-y_hat+1e-8))\n",
    "mask = torch.tensor([[[\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 0]\n",
    "]]])\n",
    "\n",
    "masked_loss_per_pixel = mask * loss_per_pixel\n",
    "loss = torch.sum(masked_loss_per_pixel) / torch.sum(mask)\n",
    "\n",
    "\n",
    "print(f\"loss per pixel          : \\n{loss_per_pixel}\")\n",
    "print(f\"masked loss per pixel   : \\n{masked_loss_per_pixel}\")\n",
    "print(f\"loss mean               : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocesses import VTFPreprocessor, ImagePreprocessor, InfodrawPreprocessor, TargetPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = TargetPreprocessor.get(\"/home/work/joono/VTFSketch/dataset/simple_data/test/targets/line_901.png\")\n",
    "infodraw = InfodrawPreprocessor.get(\"/home/work/joono/VTFSketch/dataset/simple_data/test/infodraws/color_901_out.png\")\n",
    "vtf = VTFPreprocessor.get(\"/home/work/joono/VTFSketch/dataset/simple_data/test/vtfs/color_901_fpath_of_infodraw.npz\")\n",
    "\n",
    "target = torch.tensor(target).unsqueeze(0)\n",
    "infodraw = torch.tensor(infodraw).unsqueeze(0)\n",
    "vtf = torch.tensor(vtf).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape, infodraw.shape, vtf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_W, region_B = target, (1-target)\n",
    "\n",
    "torch.set_printoptions(precision=2)\n",
    "print(f\"region_W: \\n{region_W[0, 0, 200:210, 200:210]}\")\n",
    "print(f\"region_B: \\n{region_B[0, 0, 200:210, 200:210]}\")\n",
    "print(f\"infodraw: \\n{infodraw[0, 0, 200:210, 200:210]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (infodraw < 0.99).float()\n",
    "print(f\"mask    : \\n{mask[0, 0, 200:210, 200:210]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"white pixels: {torch.sum(mask * target)}\")\n",
    "print(f\"Black pixels: {torch.sum(mask * (1-target))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_mul_target = mask * target\n",
    "print(f\"mask * target: \\n{mask_mul_target[0, 0, 200:210, 200:210]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_mul_sketch = mask * (1-target)\n",
    "print(f\"mask * 1-target: \\n{mask_mul_sketch[0, 0, 200:210, 200:210]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_infodraw = np.array((mask * target).squeeze())\n",
    "print(np_infodraw.shape)\n",
    "np_infodraw = np.stack([np_infodraw, np_infodraw, np_infodraw], axis=2)\n",
    "print(np_infodraw.shape)\n",
    "cv2.rectangle(np_infodraw, (200, 200), (210, 210), color=(0, 0, 255), thickness=2)\n",
    "plt.imshow(np_infodraw[100:400, 100:400])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VTFPredictor.load_from_checkpoint(\"/home/work/joono/VTFSketch/VTFPredictor/rmyfvx6h/checkpoints/best-checkpoint-val_f1score=0.5868685245513916.ckpt\").to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ImagePreprocessor.get(\"/home/work/joono/VTFSketch/dataset/simple_data/test/imgs/color_901.png\")\n",
    "y_hat = model(vtf=vtf, infodraw=infodraw, img=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat[0, 0, 200:210, 200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_pixel = -1 * (target * torch.log(y_hat) + (1-target) * torch.log(1-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_pixel[0, 0, 200:210, 200:210]\n",
    "loss = torch.sum(loss_per_pixel[0, 0, 200:210, 200:210]) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"loss_per_pixel: \\n{loss_per_pixel[0, 0, 200:210, 200:210]}\")\n",
    "print(f\"loss          : {torch.sum(loss_per_pixel[0, 0, 200:210, 200:210]) / torch.sum(mask[0, 0, 200:210, 200:210])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_W = mask * target\n",
    "print(f\"mask_W: \\n{mask_W[0, 0, 200:210, 200:210]}\")\n",
    "mask_W_loss_per_pixel = mask_W * loss_per_pixel\n",
    "print(f\"mask_W_loss_per_pixel: \\n{mask_W_loss_per_pixel[0, 0, 200:210, 200:210]}\")\n",
    "print(f\"mask_W_loss         : {torch.sum(mask_W_loss_per_pixel) / torch.sum(mask_W)}\")\n",
    "print(f\"mask_W_loss_w_mask  : {torch.sum(mask_W_loss_per_pixel) / torch.sum(mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_B = mask * (1-target)\n",
    "print(f\"mask_B: \\n{mask_B[0, 0, 200:210, 200:210]}\")\n",
    "mask_B_loss_per_pixel = mask_B * loss_per_pixel\n",
    "print(f\"mask_B_loss_per_pixel: \\n{mask_B_loss_per_pixel[0, 0, 200:210, 200:210]}\")\n",
    "print(f\"mask_B_loss         : {torch.sum(mask_B_loss_per_pixel) / torch.sum(mask_B)}\")\n",
    "print(f\"mask_B_loss_w_mask  : {torch.sum(mask_B_loss_per_pixel) / torch.sum(mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_pixel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_infodraw = np.array(y_hat.squeeze().detach())\n",
    "print(np_infodraw.shape)\n",
    "np_infodraw = np.stack([np_infodraw, np_infodraw, np_infodraw], axis=2)\n",
    "print(np_infodraw.shape)\n",
    "cv2.rectangle(np_infodraw, (200, 200), (210, 210), color=(0, 0, 255), thickness=1)\n",
    "plt.imshow(np_infodraw[100:400, 100:400])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models import MinFPathPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MinFPathPredictor().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:28<00:00, 36.10it/s]\n",
      "  3%|▎         | 33476/1038113 [00:08<04:11, 3986.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m infodraw \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvtf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvtf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfodraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfodraw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/joono/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/joono/anaconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/joono/VTFSketch/src/models.py:218\u001b[0m, in \u001b[0;36mMinFPathPredictor.forward\u001b[0;34m(self, vtf, img, infodraw)\u001b[0m\n\u001b[1;32m    215\u001b[0m             vtf_list\u001b[38;5;241m.\u001b[39mappend((vtf[b, :, h, w], (h, w)))  \n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vtf_vec, (h, w) \u001b[38;5;129;01min\u001b[39;00m tqdm(vtf_list):\n\u001b[0;32m--> 218\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(\u001b[43mvtf_vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    219\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer(out)\n\u001b[1;32m    220\u001b[0m     result[b, \u001b[38;5;241m0\u001b[39m, h, w] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vtf = torch.rand(2, 21, 1024, 1024).to(\"cuda\")\n",
    "infodraw = torch.rand(2, 1, 1024, 1024).to(\"cuda\")\n",
    "img = torch.rand(2, 3, 1024, 1024).to(\"cuda\")\n",
    "\n",
    "y_hat = model(vtf=vtf, img=img, infodraw=infodraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
